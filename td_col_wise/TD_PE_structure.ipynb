{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Dropout: Column wise target dropout based on the different PE-group sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the PE-wise threshold-based group lasso pruning(Yang, AAAI 2020), they consider the PE-group size as the basic pruning unit then perform the structured pruning to introduce the sparsity into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1109bd6d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;sns.set()\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this report, I'm going to reshpe the 4-D weight tensor into 2-D matrix based on the different PE-group sizes. The PE-size varying from 16 to 2. Follow the Target Dropout paper, we first load the ResNet32 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv_1_3x3.weight, shape: [16, 3, 3, 3]\n",
      "Layer: stage_1.0.conv_a.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.0.conv_b.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.1.conv_a.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.1.conv_b.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.2.conv_a.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.2.conv_b.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.3.conv_a.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.3.conv_b.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.4.conv_a.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_1.4.conv_b.weight, shape: [16, 16, 3, 3]\n",
      "Layer: stage_2.0.conv_a.weight, shape: [32, 16, 3, 3]\n",
      "Layer: stage_2.0.conv_b.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_2.1.conv_a.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_2.1.conv_b.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_2.2.conv_a.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_2.2.conv_b.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_2.3.conv_a.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_2.3.conv_b.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_2.4.conv_a.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_2.4.conv_b.weight, shape: [32, 32, 3, 3]\n",
      "Layer: stage_3.0.conv_a.weight, shape: [64, 32, 3, 3]\n",
      "Layer: stage_3.0.conv_b.weight, shape: [64, 64, 3, 3]\n",
      "Layer: stage_3.1.conv_a.weight, shape: [64, 64, 3, 3]\n",
      "Layer: stage_3.1.conv_b.weight, shape: [64, 64, 3, 3]\n",
      "Layer: stage_3.2.conv_a.weight, shape: [64, 64, 3, 3]\n",
      "Layer: stage_3.2.conv_b.weight, shape: [64, 64, 3, 3]\n",
      "Layer: stage_3.3.conv_a.weight, shape: [64, 64, 3, 3]\n",
      "Layer: stage_3.3.conv_b.weight, shape: [64, 64, 3, 3]\n",
      "Layer: stage_3.4.conv_a.weight, shape: [64, 64, 3, 3]\n",
      "Layer: stage_3.4.conv_b.weight, shape: [64, 64, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "check_point = torch.load('./decay0.0002_fp_fflf_resnet32/model_best.pth.tar', map_location='cpu')\n",
    "param = check_point['state_dict']\n",
    "\n",
    "layers = param.items()\n",
    "conv_layers = {}\n",
    "\n",
    "for k,v in layers:\n",
    "    if len(v.size()) == 4:\n",
    "        print(f\"Layer: {k}, shape: {list(v.size())}\")\n",
    "        conv_layers.update({k:v})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the second convolutional layer of the second stage as the example, reshape the 4-D tensor into 2-D matrix based on the different PE-group size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example layer: [32, 32, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "w_l = conv_layers['stage_2.1.conv_a.weight']\n",
    "print(f\"example layer: {list(w_l.size())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweep group size: [2, 4, 8, 16]\n"
     ]
    }
   ],
   "source": [
    "grp_size = [2, 4, 8, 16]\n",
    "print(f\"sweep group size: {grp_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group size=2, shape=[512, 18]\n",
      "group size=4, shape=[256, 36]\n",
      "group size=8, shape=[128, 72]\n",
      "group size=16, shape=[64, 144]\n"
     ]
    }
   ],
   "source": [
    "def reshape_2_2D(input, g):\n",
    "    w_i = input\n",
    "    num_group = w_i.size(0) * w_i.size(1) // g \n",
    "    \n",
    "    reshape_layer = w_i.view(num_group, g * w_i.size(2) * w_i.size(3))  # reshape the weight tensor into 4-D matrix\n",
    "    return reshape_layer\n",
    "\n",
    "for i, g in enumerate(grp_size):\n",
    "    w_i = w_l\n",
    "    \n",
    "    reshape_layer = reshape_2_2D(w_i, g)\n",
    "    print(f\"group size={g}, shape={list(reshape_layer.size())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input, col_size=4, alpha=0.5, gamma=0.5):\n",
    "    w_i = reshape_2_2D(input, col_size)\n",
    "    print(f\"group size={col_size}, shape={list(w_i.size())}\")\n",
    "    \n",
    "    grp_values = w_i.norm(p=2, dim=1)\n",
    "    print(f'grp values size={grp_values.size()}')\n",
    "    \n",
    "    sorted_col, indices = torch.sort(grp_values.contiguous().view(-1), dim=0)\n",
    "    print(sorted_col.size())\n",
    "\n",
    "    th_idx = int(grp_values.numel() * gamma)\n",
    "    threshold = sorted_col[th_idx]\n",
    "    print(f\"threshold L2 norm: {threshold}, idx={th_idx}\")\n",
    "    \n",
    "    mask_small = 1 - grp_values.gt(threshold).float() # mask for blocks candidates for pruning\n",
    "    mask_dropout = torch.rand_like(grp_values).lt(alpha).float()\n",
    "    \n",
    "    mask_keep = 1 - mask_small * mask_dropout\n",
    "    \n",
    "    mask_keep_2d = mask_keep.view(w_i.size(0),1).expand(w_i.size()) \n",
    "    print(mask_keep)\n",
    "    print(mask_keep_2d[6,:])\n",
    "\n",
    "    \n",
    "    mask_keep_original = mask_keep_2d.vi(input)\n",
    "    mask_keep_2d_test = mask_keep_original.resize_as_(w_i)\n",
    "    \n",
    "    return mask_keep_original, mask_keep_2d_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_keep_original_test, mask_keep_2d_test = forward(w_l)\n",
    "print(mask_keep_2d_test[4,:].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D to 4D: Try with random tensor\n",
    "x = torch.randn((4,4,2,2))\n",
    "\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_size = 2\n",
    "num_group = x.size(0) * x.size(1) // grp_size\n",
    "\n",
    "x_2d = x.resize_(num_group, g * x.size(2) * x.size(3))\n",
    "print(x_2d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
